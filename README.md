Deep Researcher Agent

An AI-powered local research assistant that can search, analyze, and synthesize information from large-scale local data sources â€” without relying on external web search APIs.
This project uses FastAPI for the backend (document processing, embeddings, and retrieval) and React for the frontend (chat interface).

ğŸ”‘ Features

    ğŸ“‚ Upload and manage local PDF documents
    
    ğŸ§  Local embedding generation using OllamaEmbeddings (no external APIs)
    
    ğŸ” Efficient document indexing and retrieval with ChromaDB
    
    ğŸªœ Multi-step reasoning with a RAG (Retrieval-Augmented Generation) pipeline
    
    ğŸ’¬ Interactive chat interface for asking research questions
    
    ğŸ“ Summarization and structured responses
    
    ğŸ”„ Support for model restarts and follow-up queries

ğŸ› ï¸ Tech Stack

  Backend (FastAPI)
  
    FastAPI + Uvicorn
    
    LangChain (document loaders, retrievers, RAG pipeline)
    
    Ollama for local LLM embeddings & reasoning
    
    ChromaDB for vector storage
  
  Frontend (React)
  
    React + Vite
    
    Axios (API calls)
    
    ReactMarkdown (for rich text display)

âš™ï¸ Setup Instructions

  1ï¸âƒ£ Clone the repository
  
    git clone https://github.com/your-username/deep-researcher-agent.git
    cd insightai
  
  2ï¸âƒ£ Backend Setup (FastAPI)
  
    cd ModelServer
    pip install -r requirements.txt
    uvicorn main:app --reload
  
  
  3ï¸âƒ£ Frontend Setup (React + Vite)
  
    cd client
    npm install
    npm run dev


ğŸŒŸ Future Enhancements

    ğŸ“‘ Export research reports (PDF/Markdown)
    
    ğŸ”„ Interactive query refinement (follow-up clarifications)
    
    ğŸ§© Explainable reasoning steps
